# RL Filter - First 100 Lines Summary

## What These Lines Do
The first 100 lines establish the core feature extraction system that converts URLs, user missions, and webpage content into numerical data that the AI can understand and learn from.

## How They Do It

### Lines 1-23: Foundation Setup
- Imports necessary libraries (numpy, torch, sqlite3, etc.)
- Sets up the infrastructure for machine learning, database storage, and text processing

### Lines 24-30: URLFeatureExtractor Class
- Creates the main class responsible for converting text into numbers
- Philosophy: "Pure numerical feature extraction - no hardcoded rules"
- Lets the AI learn patterns instead of imposing human assumptions

### Lines 32-46: Simple Entry Point (extract_features)
- Provides a basic way to extract features when you only have a URL and mission
- Creates minimal metadata with empty placeholders for title, description, etc.
- Delegates to the full extraction pipeline

### Lines 48-79: Core Feature Pipeline (extract_features_from_metadata)
- **Main orchestrator** that creates the 1181-dimensional feature vector
- Combines 6 different feature types:
  1. URL text features (384 dims) - URL structure analysis
  2. Mission text features (384 dims) - User goal analysis  
  3. Content text features (384 dims) - Webpage content analysis
  4. Dynamic URL features (15 dims) - Domain/path characteristics
  5. Content metadata features (10 dims) - Page quality indicators
  6. Time features (4 dims) - Current time context

### Lines 81-100: URL Analysis Begins (_extract_url_text_features)
- Starts extracting 384 features from the URL itself
- Analyzes URL structure: length, path segments, parameters, special characters
- Detects protocol (HTTPS), domain types (.edu, .gov, .com), and character composition
- Creates 50 basic structural features, with 334 more complex features to follow

## How This Helps Achieve Software Purpose

### 1. Mission-Aware Filtering
- Takes the user's specific mission text and converts it to numerical features
- Allows the AI to understand context: "learn Python" vs "entertainment" missions
- Enables personalized decisions based on what the user wants to accomplish

### 2. Content-Aware Decisions  
- Analyzes actual webpage content (title, description, text) not just domain names
- Can distinguish between productive YouTube videos vs distracting ones
- Goes beyond simple blocklists to understand content relevance

### 3. Adaptive Learning Foundation
- Creates rich numerical representations (1181 features) that capture nuanced patterns
- No hardcoded "good/bad" website lists - lets AI learn from user feedback
- Supports the binary rating system (1=productive, 0=distracting) mentioned in aim.txt

### 4. Real-Time Decision Making
- Efficiently processes URLs during browsing without external API calls
- Maintains compatibility with pretrained models (exact 1181-dimension requirement)
- Enables the proxy to make instant allow/block decisions during web browsing

### 5. Contextual Intelligence
- Combines URL structure + mission intent + content analysis + time context
- Example: StackOverflow at 2 PM during "debug Python code" mission = likely productive
- Example: Same site at 11 PM during "write report" mission = possibly distracting

This feature extraction system is the foundation that enables Anchorite to provide intelligent, mission-specific website filtering rather than crude domain blocking.

---

# RL Filter - Lines 100-200 Summary

## What These Lines Do
Lines 100-200 complete the URL analysis and implement the mission and content text feature extraction - creating the three core 384-dimensional feature sets that form the heart of the AI's understanding.

## How They Do It

### Lines 100-119: Completing URL Text Features (384 dims total)
**URL Pattern Features (100 features):**
- Platform detection: counts of 'youtube', 'reddit', 'github', 'stackoverflow', 'wikipedia'
- Content type hints: 'learn', 'tutorial', 'course', 'video', 'watch', 'search'
- Quality indicators: detects 'api', 'doc', 'guide' vs 'game', 'play', 'fun'
- Path complexity: counts forward slashes to measure URL depth

**Hash-Based Features (234 features):**
- Converts URL words into numerical fingerprints using hash functions
- Uses first 5 words from cleaned URL text
- Normalizes hash values to 0-1 range for consistent ML input
- Creates unique patterns the AI can learn to associate with productivity

### Lines 121-163: Mission Text Analysis (_extract_mission_text_features)
**Basic Text Characteristics (50 features):**
- Mission length, word count, vocabulary diversity
- Punctuation analysis: spaces, periods, commas, questions, colons
- Character composition: letters vs numbers vs special characters
- Word complexity: average length, maximum word length

**Mission Type Detection (100 features):**
- Learning missions: 'learn', 'study', 'understand', 'master', 'tutorial'
- Work missions: 'work', 'job', 'project', 'task', 'complete'
- Creative missions: 'create', 'build', 'develop', 'design', 'make'
- Research missions: 'research', 'find', 'information', 'data', 'explore'
- Skill missions: 'skill', 'practice', 'improve', 'training', 'course'
- Mission complexity: word count, questions (?), sentences (.)

**Mission Hash Features (234 features):**
- Each word in the mission gets converted to a unique numerical signature
- Creates patterns the AI can learn to match with relevant websites
- Handles variable-length missions by padding with "empty" values

### Lines 165-200: Content Text Analysis Begins (_extract_content_text_features)
**Basic Content Characteristics (50 features):**
- Content length, word count, vocabulary richness, sentence count
- Punctuation density: spaces, periods, commas, quotes, questions
- Character analysis: letters, digits, special characters
- Word complexity: average length, long words (>10 chars), technical indicators

**Content Quality Detection (starts at line 186):**
- Title/heading indicators: structured content detection
- Description quality: summary and about sections
- Tutorial content: 'guide', 'how to', 'step' indicators
- Documentation: 'docs', 'api', 'reference' detection
- Educational content: 'learn', 'course', 'lesson', 'education'
- Structure analysis: bullet lists, code content, question density

## How This Achieves Software Purpose

### 1. Deep URL Understanding
- Goes beyond domain blocking to analyze URL structure and path content
- Detects educational platforms (stackoverflow, github) vs entertainment hints
- Hash features create unique fingerprints for similar URL patterns

### 2. Mission-Centric Intelligence
- Extracts user intent: learning vs work vs creative vs research goals
- Measures mission complexity and specificity (meets 50+ character requirement)
- Creates numerical representations that match missions to relevant content

### 3. Content Quality Assessment
- Analyzes actual webpage text content, not just URL or domain
- Detects structured, educational content (tutorials, documentation, guides)
- Identifies technical content that might be relevant to coding/work missions

### 4. Adaptive Pattern Recognition
- Hash features enable the AI to learn associations without hardcoded rules
- Each mission type gets distinct numerical signatures
- Content structure analysis helps distinguish quality information from noise

### 5. Real-World Mission Support
- Supports the user workflow: specific mission → relevant website detection
- Enables the binary feedback system (1=productive, 0=distracting) from aim.txt
- Creates foundation for learning "YouTube Python tutorial" = productive vs "YouTube cat videos" = distracting

This section transforms human language (URLs, missions, content) into the numerical intelligence that enables Anchorite's AI to make contextual, mission-aware filtering decisions in real-time.

---

# RL Filter - Lines 200-300 Summary

## What These Lines Do
Lines 200-300 complete the feature extraction pipeline by finishing content text analysis and implementing the remaining feature extraction functions that create the final components of the 1181-dimensional vector.

## How They Do It

### Lines 200-215: Completing Content Text Features (384 dims total)
**Final Content Quality Features (completes the 100-feature set):**
- Combines content type indicators: title, description, tutorial, documentation, learning content
- Structure analysis: lists (bullets/dashes), code content detection, question density
- Complexity measures: sentence count, longest word length (technical terms indicator)

**Content Hash Features (234 features):**
- Takes first 20 words from content text for consistency
- Converts each word position into a unique numerical signature
- Creates learnable patterns: "tutorial python programming" gets different hash than "funny cat video"
- Normalizes hash values to 0-1 range for stable ML input

### Lines 217-224: Domain Extraction Utility (_extract_domain)
**Clean Domain Parsing:**
- Strips protocol: "https://www.github.com/user/repo" → "github.com"
- Removes www prefix: "www.stackoverflow.com" → "stackoverflow.com"
- Extracts base domain for consistent analysis across different URL formats

### Lines 226-258: Content Text Creation (_create_content_text_from_metadata)
**Unified Content Assembly:**
- **Title**: "Title: {page_title}" if available
- **Description**: "Description: {first_200_chars}" from meta tags
- **Keywords**: "Keywords: {keyword1 keyword2...}" (max 10)
- **Content**: "Content: {first_200_chars}" of extracted text
- **Fallback**: If no content metadata, uses cleaned URL as "Website: domain path words"

**Smart Content Combination:**
- Joins multiple sources with " | " separator
- Limits each section to prevent feature bloat (200 chars max)
- Creates rich text input for the content feature extractor

### Lines 260-292: Dynamic URL Features (_extract_dynamic_url_features) - 15 dims
**Domain Intelligence (no hardcoded platforms):**
- Domain complexity: subdomain count (api.docs.github.com = 4 parts)
- Authority indicators: .edu (educational), .org (organization), .gov (government)
- Documentation detection: "docs" or "documentation" in domain

**Path Analysis:**
- Path depth: counts "/" to measure URL specificity
- Content type detection: "/watch", "/video", "/article", "/post", "/blog"
- Functionality: "/search", "/results", "/user", "/profile"

**URL Structure:**
- Query parameter count: complex URLs often indicate specific content
- Search detection: "q=" or "search=" parameters
- Security: HTTPS indicator, URL length, parameter density

### Lines 294-314: Content Metadata Features (_extract_content_features) - 10 dims
**Page Quality Indicators:**
- Basic content: has title, has description, keyword count
- Content richness: total length (normalized to 0-1 scale)

**Media & Interaction Analysis:**
- Visual content: image count, video presence
- Navigation: internal links, external links (normalized)
- User interaction: form presence (signup, contact, etc.)
- Performance: page response time (site quality indicator)

### Lines 316-332: Time Context Features (_extract_time_features) - 4 dims
**Temporal Context:**
- **Hour of day**: 0.0 (midnight) to 1.0 (11 PM) - captures daily patterns
- **Day of week**: 0.0 (Monday) to 1.0 (Sunday) - weekend vs weekday context
- **Work hours**: 1.0 during 9 AM-5 PM, 0.0 otherwise
- **Weekend flag**: 1.0 on Saturday/Sunday, 0.0 on weekdays

## How This Achieves Software Purpose

### 1. Complete Feature Pipeline
- Finishes the 1181-dimensional vector: 384+384+384+15+10+4 = 1181
- Each component captures different aspects: text, structure, quality, timing
- Maintains exact compatibility with pretrained model requirements

### 2. Context-Aware Content Analysis
- Rich content representation from multiple metadata sources
- Distinguishes between educational content, entertainment, and productivity tools
- Hash features enable learning complex content patterns

### 3. Intelligent URL Understanding
- Goes beyond domain blocking to analyze URL structure and purpose
- Detects educational institutions, documentation sites, specific content types
- Captures URL complexity that correlates with content specificity

### 4. Temporal Intelligence
- Incorporates time context: work hours vs evening browsing patterns
- Enables learning that same site might be productive during work hours, distracting at night
- Supports the user's mission-based session workflow from aim.txt

### 5. Quality-Based Filtering
- Page quality indicators help distinguish authoritative content from low-value pages
- Media analysis helps detect educational videos vs entertainment content
- Response time indicates site reliability and professionalism

### 6. Adaptive Learning Foundation
- Hash-based features create unique fingerprints without hardcoded assumptions
- Multiple feature types enable the AI to learn complex productivity patterns
- Supports the binary feedback system (1=productive, 0=distracting) for continuous improvement

This completes the feature extraction engine that transforms raw web requests into intelligent, contextual data that enables Anchorite's AI to make nuanced productivity decisions aligned with the user's specific mission and current context.

---

# RL Filter - Lines 300-600 Summary

## What These Lines Do
Lines 300-600 implement the core AI decision-making system, including the neural network architectures, the main RLFilter class, database management, model loading, real-time filtering decisions, and the feedback learning system.

## How They Do It

### Lines 335-355: ProductivityClassifier Neural Network
**Architecture:**
- **Input Layer**: 1181 features → 256 neurons
- **Hidden Layer 1**: 256 → 128 neurons with ReLU activation & 20% dropout
- **Hidden Layer 2**: 128 → 64 neurons with ReLU activation & 20% dropout  
- **Output Layer**: 64 → 1 neuron with Sigmoid activation (0.0-1.0 probability)

**Purpose:**
- This is the **core AI brain** that makes productivity predictions
- Takes the 1181-dimensional feature vector and outputs productivity probability
- Sigmoid ensures output is between 0-1: 0=distracting, 1=productive

### Lines 357-380: DQNNetwork (Deep Q-Network)
**Architecture:**
- More complex network: 1181 → 512 → 512 → 256 → 128 → 2 outputs
- Higher dropout rates (30%, 30%, 20%)
- **Output**: 2 actions (0=block, 1=allow) for reinforcement learning

**Current Status**: Defined but **not actively used** - the system uses ProductivityClassifier instead

### Lines 382-414: RLFilter Class Initialization
**Core Setup:**
- **Model Loading**: Loads `best_pretrained_model.pth` weights into ProductivityClassifier
- **Device Detection**: Uses GPU if available, falls back to CPU
- **Decision Threshold**: 0.5 (probability > 0.5 = allow, ≤ 0.5 = block)
- **Threading**: Thread lock for safe concurrent access
- **Statistics Tracking**: Total decisions, correct decisions, feedback count, accuracy

**Dependencies:**
- URLFeatureExtractor instance for converting URLs to features
- SQLite database for caching decisions and feedback
- Logging system for monitoring decisions

### Lines 416-447: Database Infrastructure (_setup_database)
**Decisions Table:**
- Stores every filtering decision with URL, mission, features, action, confidence
- Tracks user feedback (correct/incorrect) and rewards
- Enables analysis of AI performance and learning from mistakes

**Training Data Table:**
- Repository for labeled examples from various sources
- Supports future model retraining and improvement
- Maintains data provenance and timestamps

### Lines 453-467: Model Loading System (_load_model)
**Smart Loading:**
- **Primary**: Loads `best_pretrained_model.pth` if available
- **Fallback**: Uses randomly initialized model if file missing
- **Error Handling**: Graceful degradation with logging
- **Eval Mode**: Sets model to inference mode (no gradient computation)

**File Location**: Expects model file in same directory as `rl_filter.py`

### Lines 478-504: Mission Management & URL Decision Entry Point
**Mission Setting:**
- Thread-safe mission text storage
- Logging of mission changes for audit trail

**URL Decision Interface** (`is_url_allowed`):
- **Simple Entry**: Takes just URL string
- **Metadata Creation**: Builds minimal metadata structure with empty fields
- **Delegation**: Calls full metadata-based decision method

### Lines 506-549: Core AI Decision Engine (`is_url_allowed_with_metadata`)
**The Decision Pipeline:**
1. **Mission Check**: Returns False if no mission set
2. **Feature Extraction**: Converts metadata + mission → 1181 features
3. **Neural Network Inference**: Features → productivity probability
4. **Threshold Decision**: probability > 0.5 → allow, else block
5. **Decision Storage**: Saves for potential user feedback
6. **Enhanced Logging**: URL, domain, title with confidence score

**Thread Safety**: Uses lock to prevent concurrent access issues
**Error Handling**: Returns False (block) on any processing error

### Lines 551-596: Feedback Learning System
**Decision Storage** (`_store_decision`):
- Saves URL, mission, raw features, action, confidence, timestamp
- Stores features as binary blob for exact reproduction
- Enables later feedback association

**User Feedback Processing** (`provide_feedback`):
- **Feedback Reception**: Accepts URL + correct/incorrect flag
- **Database Update**: Links feedback to most recent decision
- **Statistics Update**: Tracks accuracy and feedback count
- **Reward Assignment**: +1.0 for correct, -1.0 for incorrect decisions

### Lines 598-618: Performance Monitoring
**Statistics Collection**:
- **Periodic Saving**: Every 100 feedback items saves stats to JSON
- **Accuracy Calculation**: correct_decisions / total_feedback
- **Performance Metrics**: Total decisions, feedback count, model type

**Stats Output**: Returns comprehensive performance data for monitoring

### Lines 621-644: Global Interface Functions
**Singleton Pattern**:
- `get_rl_filter()`: Creates/returns single global instance
- Ensures consistent state across entire application

**Simple API**:
- `set_mission(text)`: Configure user's current mission
- `is_url_allowed(url)`: Make filtering decision
- `provide_feedback(url, correct)`: Submit user feedback

## How This Achieves Software Purpose

### 1. Real-Time Productivity Filtering
- **Instant Decisions**: Neural network inference in milliseconds
- **Mission-Aware**: Every decision considers user's specific goal
- **Contextual Intelligence**: Uses URL structure, content, timing for nuanced decisions

### 2. Adaptive Learning Through Feedback
- **Binary Rating System**: Implements the 1=productive, 0=distracting system from aim.txt
- **Decision Memory**: Stores every decision for feedback association
- **Continuous Improvement**: Tracks accuracy and learns from mistakes

### 3. Mission-Based Session Support
- **Dynamic Mission Setting**: Supports changing goals throughout day
- **Persistent Context**: Remembers mission for entire session
- **Flexible Interface**: Works with proxy, GUI, or direct integration

### 4. Robust AI Infrastructure
- **Pretrained Intelligence**: Uses sophisticated neural network trained on productivity patterns
- **Graceful Degradation**: Works even if pretrained model unavailable
- **Thread-Safe**: Supports concurrent requests from proxy system

### 5. Data-Driven Decision Making
- **Feature-Rich Analysis**: 1181-dimensional understanding of each request
- **Evidence-Based**: Decisions based on URL structure, content, mission relevance, timing
- **Transparent Confidence**: Provides probability scores for decision transparency

### 6. Integration with User Workflow
- **Proxy Integration**: Seamlessly filters web traffic during browsing
- **Feedback Collection**: Captures user corrections for system improvement
- **Session Analytics**: Tracks performance and provides insights

This section transforms the feature extraction intelligence into a complete, production-ready AI filtering system that implements Anchorite's core mission-aware productivity filtering with continuous learning from user feedback.
